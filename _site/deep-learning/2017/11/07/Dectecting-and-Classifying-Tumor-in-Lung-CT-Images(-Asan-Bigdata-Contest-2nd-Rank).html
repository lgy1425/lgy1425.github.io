<!DOCTYPE html>
<html lang="en">

  <head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  <title>Detecting and Classifying Tumor in Lung CT Images (Asan Bigdata Contest 2nd Rank)</title>
  <meta name="description" content="In January 2017, AMC(Asan Medical Center, Korea) and Microsoft Korea held medical bigdata analysis contest. This research introduced in this article is about...">

  <link rel="stylesheet" href="/assets/main.css">
  <link rel="canonical" href="http://localhost:4000/deep-learning/2017/11/07/Dectecting-and-Classifying-Tumor-in-Lung-CT-Images(-Asan-Bigdata-Contest-2nd-Rank).html">
  <link rel="alternate" type="application/rss+xml" title="GY dev" href="/feed.xml">
  
  
</head>


  <body>

    <header class="site-header" role="banner">

  <div class="wrapper">
    
    
    <a class="site-title" href="/">GY dev</a>
  
    
      <nav class="site-nav">
        <input type="checkbox" id="nav-trigger" class="nav-trigger" />
        <label for="nav-trigger">
          <span class="menu-icon">
            <svg viewBox="0 0 18 15" width="18px" height="15px">
              <path fill="#424242" d="M18,1.484c0,0.82-0.665,1.484-1.484,1.484H1.484C0.665,2.969,0,2.304,0,1.484l0,0C0,0.665,0.665,0,1.484,0 h15.031C17.335,0,18,0.665,18,1.484L18,1.484z"/>
              <path fill="#424242" d="M18,7.516C18,8.335,17.335,9,16.516,9H1.484C0.665,9,0,8.335,0,7.516l0,0c0-0.82,0.665-1.484,1.484-1.484 h15.031C17.335,6.031,18,6.696,18,7.516L18,7.516z"/>
              <path fill="#424242" d="M18,13.516C18,14.335,17.335,15,16.516,15H1.484C0.665,15,0,14.335,0,13.516l0,0 c0-0.82,0.665-1.484,1.484-1.484h15.031C17.335,12.031,18,12.696,18,13.516L18,13.516z"/>
            </svg>
          </span>
        </label>

        <div class="trigger">
          
            
            
          
            
            
            <a class="page-link" href="/about/">About</a>
            
          
            
            
          
            
            
          
            
            
          
        </div>
      </nav>
    
  </div>
</header>


    <main class="page-content" aria-label="Content">
      <div class="wrapper">
        <article class="post" itemscope itemtype="http://schema.org/BlogPosting">

  <header class="post-header">
    <h1 class="post-title" itemprop="name headline">Detecting and Classifying Tumor in Lung CT Images (Asan Bigdata Contest 2nd Rank)</h1>
    <p class="post-meta">
      <time datetime="2017-11-07T00:00:00+09:00" itemprop="datePublished">
        
        Nov 7, 2017
      </time>
      </p>
  </header>

  <div class="post-content" itemprop="articleBody">
    <p>In January 2017, AMC(Asan Medical Center, Korea) and Microsoft Korea held medical bigdata analysis contest. This research introduced in this article is about one of the 5 projects in the contest and was ranked as 2nd prize. This article introduce shortly research’s method, process and results</p>

<h3>1. Subject</h3>

<p>This research did assignment that deep learning models detects lung tumors and diagnosing whether the tumors is benign or malignant from CT images taking human’s lung. Until now, only trained and skillful medical staffs can diagnosing lung cancers with CT images. But, trained deep learning models are expected to be able to easily and quickly diagnosing lung cancers. That will be able to reduce cost and time of diagnosing lung cancers in CT images.</p>

<h3>2. Data Set</h3>

<p>All of data set used in this research are produced by medical big data analysis contest hold by Asan Medical Center. Produced data was human body CT image around lung and ROI(Region of Interest) mask images made by professional medical staffs in medical center. Data format was dicom files. Training data set was 300 patients’ CT images and ROI mask, 93 patients had benign tumors and 207 patients had malignant tumors. Validation data set for evaluating participants of contest was 62 patients’ CT images and ROI mask, composed of 21 patients having benign tumors and 42 patients having malignant tumors.
All of CT images had 512 x 512px resolution. All pixel values are integers between 0 and 2048 and images had only one channel and are black-white images. Each patient had 50 – 70 frames and an interval of frames is about 5mm. ROI mask’s resolution was same with CT image’s and ROI mask is black-white image.</p>

<p><img src="https://i.imgur.com/ytHwcku.png" alt="" />
<img src="https://i.imgur.com/bABnfoV.png" alt="" /></p>

<h3>3. Method</h3>
<p>Processes are implemented with python(2.7.13) language and python basic package were used. Some python packages and libraries such as pydicom for processing dicom format files, Pillow for processing images, and numpy for math and matrix operations. For deep learning implementation, Tensorflow(http://tensorflow.org) was used.</p>
<h3>Sliding Window</h3>
<p>Sliding window method was applied to this research for analyzing images. Sliding window method is that kernel(window) slides on whole images from end to end with constant stride and each kernel is analyzed. The reason that sliding window method was applied is that ROIs(tumors) occupied small area(up to width, height 50px) in CT images(512x512px size) and all of ROIs can be contained in one kernel. And CT images was not very high resolution images, so time consuming problem was not serious for sliding window method.</p>

<p><img src="https://i.imgur.com/hO9Cwx6.png" alt="" /></p>

<p>Patches from sliding window method is 50x50px size with 10px strides. About 25,000 patches are made in each CT image. Cropped patches are divided into 3 classes label using ROI mask data. All patches are divided into 3 class, Not ROI(patches not containing ROI), Benign ROI(patches containing benign ROI), Malignant ROI(patches containing malignant ROI). Training data was composed of these 3 class patches. From 300 patients’ CT images, about 3,000 Benign ROI patches, about 19,000 Malignant ROI patches, about 20,000 Not ROI patches randomly extracted from millions patches compose training data for deep learning.</p>

<p><img src="https://i.imgur.com/ltzdrzM.png" alt="" /></p>

<h3>Data Augmentation</h3>
<p>Training data extracted from sliding window method was composed of about 20,000 Not ROI , 3,000 Benign ROI, 19,000 Malignant ROI. Normally, unbalance between numbers of training data’ classes can generate overfitting to CNN models. So, the number of Benign ROI class data was augmented by data augmentation method. There are some usual data augmentation technique for images such as random crop, flip, rotation, blurring, elastic deformation, dropout, zoom in and so on. In this research, horizontal flip, zoom in, 30 degree rotation, 45 degree rotation, blurring were used as data augmentation technique because CT images had up and down side and deformation of tumor shape can adversely affect accuracy of diagnosing.</p>

<p><img src="https://i.imgur.com/96HMRgj.png" alt="" /></p>

<p>Due to data augmentation, numbers of 3 classes data(Not ROI, Benign ROI, Malignant ROI) were balanced. Each number of 3 classes is about 20,000 in training data set.</p>

<h3>Network Modeling</h3>
<p>A customized CNN model was modeled for classifying 50x50px size patches into 3 classes. Usually used CNN models are customized for CT images. In first time, original VGG 16 model was used for training CNN model, but model couldn’t properly learn CT images. It was too deeper to learning CT image’s features. If model is too deep compared to complexity of data, it is hard for model to learn data’s features. Each patch is 50x50px size and one channel black-white image and it is similar with MNIST dataset. For MNIST data set, very simple CNN model can get over 99% classification accuracy. So the model for classifying patches into 3 classes was shallower model than VGG model and has similar architecture with VGG mdoel.</p>

<p><img src="https://i.imgur.com/4YePA3N.png" alt="" />
<img src="https://i.imgur.com/hYM9poG.png" alt="" /></p>

<p>As seen in architecture image above, after passing through 2 convolution layers, max pooling is operated. After that, first max pooling are followed by 3 convolution layers. The last convolution layer is followed by max pooling operation. And next layers are 2 fully connected layers. Soft max operation is applied to last fully connected layer and its output is probability for each class. All of convolution layers’ filters are 3x3px size and stride size is 1px. The first 2 convolution layers’ channel is 54, the last 3 convolution layers’ channel is 108. Two max pooling operations’ kernel is 2x2px size and stride size is 2px. After max pooling operation, feature map become half size feature map. After second max pooling operation, feature map’s size is 13x13px and the number of channel is 108. This feature map is flatten to vector and the vector is connected to 2 fully connected layers. The first fully connected layer’s elements’ number is 432, the last fully connected layer’s elements’ number is 3 and same with the number of classes. The last output vector with softmax operation is probability of each class. All of layers have ReLU(Rectified Linear Unit)[32] operation as activation function. Detailed parameters is shown on below table.</p>

<p><img src="https://i.imgur.com/9z7jAoA.png" alt="" /></p>

<h3>Preventing Overfitting</h3>

<p>Overfitting means that trained deep learning models can’t be generalized for other data not trained and trained model can predict training data set, but can’t for validation data set. For preventing overfitting, one of the most popular techniques is data augmentation referred above. Balance between numbers of classes with data augmentation makes generalized CNN models. And some techniques that makes weights in CNN models be regularized are usually used for preventing overfitting. In this research, dropout[32] are applied to CNN model for preventing overfitting. Dropout means that some of weights in CNN models are randomly dropped out in training process for preventing some of weights much bigger than other weights and regularizing weights. In CNN models in this research, dropout was applied at two max pool operations and first fully connected layer. The rate of dropout in convolution layer is 30% and the rate of dropout in fully connected layer is 50%.</p>

<h3>Training</h3>

<p>The CNN model made up above was trained with about 60,000 patches. Training process is minimizing cost defined as cross entropy between 3 classes labeling vectors(Not ROI [1,0,0], Benign ROI [0,1,0], Malignant [0,0,1]) and softmax result passed through the CNN model. AdamOptimizer was used as optimizer for training. The learning rate of training was constant and 0.0005. Training batches were 400 patches randomly extracted from training data set and an epoch was defined that CNN model was trained for all of 60,000 patches. After training CNN model in 200 epochs, cross entropy was converged to 0.55. Training CNN model with 200 epochs data set took about 14 hours.</p>

<p><img src="https://i.imgur.com/KmhVCSy.png" alt="" /></p>

<h3>ROI detection with trained model</h3>

<p>If trained CNN model can classify patches into 3 classes with over 90 % accuracy, next step is detecting region of tumors in CT images with trained model. As seen in Fig 11, firstly patches are extracted from CT image in 50x50px size and 10px size stride, same with preprocessing(slding window). Each patch is labeled into 3 classes : Not ROI : 0, Benign ROI : 1, Malignant ROI : 2. As seen in downside of Fig 12, these labels were labeled on a new image having same size with a CT image. In labeled the image, region where 1 or 2 labels are overlapped is detected as ROIs.</p>

<p><img src="https://i.imgur.com/E1MIxCg.png" alt="" />
<img src="https://i.imgur.com/qDoWVP4.png" alt="" /></p>

<h3>Benign/Malignant Classification with trained model</h3>

<p>In the region detected as ROI, CNN model predict whether the ROIs is benign or malignant with majority voting among 1 or 2 labels. The threshold of majority voting can be adjusted according to sensitivity.</p>

<h3>4. Result</h3>

<p>The result of this research is from validation data set composed of 62 patients’ CT images and ROI mask. In ROI detection result, detected ROI is masked with red and compared to mask professional medical staffs mdae. Diagnosing tumor as benign or malignant was done with majority voting in CT images in one patient. Diagnosing a CT image took about 5 seconds in GPU hardware environment.</p>

<h3>ROI Detection</h3>

<p><img src="https://i.imgur.com/SDb4lgN.png" alt="" /></p>

<p>Trained model detected some region probably contains ROI and masked it with red color. As Examples seen in Fig 12, big enough ROIs were completely detected by CNN model, some small ROIs were missed or other region not containing ROI were recommended . But CNN model did not miss all of tumors in one patient’s CT frames.</p>

<h3>Benign/Malignant Classification</h3>

<p>Among 62 patients in validation data set, 57 patients are correctly classified into benign and malignant. Its accuracy was 92%. 3 benign patients were diagnosed as malignant, 2 malignant patients were diagnosed as benign. Sensitivity for malignant tumor was 0.95 and specificity for benign was 0.9.</p>

<p><img src="https://i.imgur.com/ElLc766.png" alt="" /></p>

<h3>5. Conclusion</h3>

<p>The sliding window method employed in this research is not generally better than other CNN object detection methods such as RCNN based network and YOLO. But in environment that objects(ROIs) is so small, sliding window can be effective. The training data’s volume was too small to be applied to deep learning method. But sliding window method and data preprocessing could make it sufficient to be applied to CNN models. It is expected to get more accurate model with huge volume of data and balance between benign and malignant data. Also, for solving difficulties of detecting small ROI, variety of sliding window patch’s size will be applied next time.</p>


  </div>

  
</article>

      </div>
    </main>

    <footer class="site-footer">

  <div class="wrapper">

    <h2 class="footer-heading">GY dev</h2>

    <div class="footer-col-wrapper">
      <div class="footer-col footer-col-1">
        <ul class="contact-list">
          <li>
            
              GY dev
            
            </li>
            
            <li><a href="mailto:lgy1425@gmail.com">lgy1425@gmail.com</a></li>
            
        </ul>
      </div>

      <div class="footer-col footer-col-2">
        <ul class="social-media-list">
          
          <li>
            <a href="https://github.com/lgy1425"><span class="icon icon--github"><svg viewBox="0 0 16 16" width="16px" height="16px"><path fill="#828282" d="M7.999,0.431c-4.285,0-7.76,3.474-7.76,7.761 c0,3.428,2.223,6.337,5.307,7.363c0.388,0.071,0.53-0.168,0.53-0.374c0-0.184-0.007-0.672-0.01-1.32 c-2.159,0.469-2.614-1.04-2.614-1.04c-0.353-0.896-0.862-1.135-0.862-1.135c-0.705-0.481,0.053-0.472,0.053-0.472 c0.779,0.055,1.189,0.8,1.189,0.8c0.692,1.186,1.816,0.843,2.258,0.645c0.071-0.502,0.271-0.843,0.493-1.037 C4.86,11.425,3.049,10.76,3.049,7.786c0-0.847,0.302-1.54,0.799-2.082C3.768,5.507,3.501,4.718,3.924,3.65 c0,0,0.652-0.209,2.134,0.796C6.677,4.273,7.34,4.187,8,4.184c0.659,0.003,1.323,0.089,1.943,0.261 c1.482-1.004,2.132-0.796,2.132-0.796c0.423,1.068,0.157,1.857,0.077,2.054c0.497,0.542,0.798,1.235,0.798,2.082 c0,2.981-1.814,3.637-3.543,3.829c0.279,0.24,0.527,0.713,0.527,1.437c0,1.037-0.01,1.874-0.01,2.129 c0,0.208,0.14,0.449,0.534,0.373c3.081-1.028,5.302-3.935,5.302-7.362C15.76,3.906,12.285,0.431,7.999,0.431z"/></svg>
</span><span class="username">lgy1425</span></a>

          </li>
          

          
        </ul>
      </div>

      <div class="footer-col footer-col-3">
        <p>GY&#39;s tech blog, Deep Learning, Machine Learning, Web Application, Mobile Application, Data Analysis, Computer Vision</p>
      </div>
    </div>

  </div>

</footer>


  </body>

</html>
